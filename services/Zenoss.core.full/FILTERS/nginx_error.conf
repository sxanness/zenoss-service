# nginx error logs

grok {
    # Matches messages like the messages below:
    # 2017/08/30 20:17:37 [error] 85#0: *41 upstream prematurely closed connection while reading response header from upstream, client: 172.17.42.1, server: , request: "HEAD /ping/status/performance HTTP/1.1", upstream: "http://127.0.0.1:8888/ping/status", host: "localhost:8080"
    # 2017/08/31 14:58:09 [notice] 4802#0: signal process started

    match => [ "message", "^(?<datetime>%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME}) \[%{LOGLEVEL:loglevel}\] %{NUMBER:pid}#%{NUMBER:tid}:%{SPACE}(\*%{NUMBER:cid})?%{SPACE}%{GREEDYDATA:message}$" ]
}

# Elasticsearch doesn't like the format of datetime.
# This filter parses the datetime field into a time value,
# removes the datetime field from the data, and
# then uses the parsed value as the "@timestamp" for the message.
date {
    match => [ "datetime", "YYYY/MM/dd HH:mm:ss" ]
    remove_field => ["datetime"]
}

mutate {
    uppercase => [ "loglevel" ]
}
